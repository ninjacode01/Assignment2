{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1LdmvdGpXp-wDu3ht2JccjS-noXtK8KCa",
      "authorship_tag": "ABX9TyNU204bDzEMpAqKDDy0X+xZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ninjacode01/Assignment2/blob/main/ass_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Named Entity Recognition"
      ],
      "metadata": {
        "id": "3dw4688vJ6LC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets start with reading and pre-processing the training dataset\n"
      ],
      "metadata": {
        "id": "lyTqmUiGKFa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone 'https://github.com/ninjacode01/Assignment2'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpBP7EM2KQ2K",
        "outputId": "f510d213-ded8-4c03-8e6a-a5bc5093d9bd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Assignment2'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 18 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (18/18), 728.04 KiB | 3.59 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Assignment2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwP8VpC9Mwlk",
        "outputId": "61d1254f-1041-481c-cd14-b8f34d004816"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Assignment2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(filename):\n",
        "    with open(filename, \"r\") as file:\n",
        "        text = file.readlines()\n",
        "    return text\n",
        "\n",
        "def process_text(text):\n",
        "    X = []\n",
        "    Y = []\n",
        "    sentenceX = []\n",
        "    sentenceY = []\n",
        "    for line in text:\n",
        "        split = line.split(\" \")\n",
        "        if len(split) > 1:\n",
        "            sentenceX.append(split[0].lower())\n",
        "            sentenceY.append(split[1].replace(\"\\n\", \"\"))\n",
        "        else:\n",
        "            X.append(sentenceX)\n",
        "            Y.append(sentenceY)\n",
        "            sentenceX = []\n",
        "            sentenceY = []\n",
        "    return X, Y\n",
        "\n",
        "text = read_file(\"data/train.txt\")\n",
        "X, Y = process_text(text)\n",
        "\n",
        "testing= read_file(\"data/test.txt\")\n",
        "X_test, Y_test= process_text(testing)"
      ],
      "metadata": {
        "id": "SDHXo6ggMudj"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags={}\n",
        "k=0\n",
        "for i in range(len(Y)):\n",
        "  for j in range(len(Y[i])):\n",
        "    if tags.get(Y[i][j])==None:\n",
        "      tags[Y[i][j]]= k\n",
        "      k+=1\n",
        "tags\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfQWWMX-aSw5",
        "outputId": "5a3a8497-6ff6-4446-b977-7878f8b48c94"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-NP': 0,\n",
              " 'B-PP': 1,\n",
              " 'I-NP': 2,\n",
              " 'B-VP': 3,\n",
              " 'I-VP': 4,\n",
              " 'B-SBAR': 5,\n",
              " 'O': 6,\n",
              " 'B-ADJP': 7,\n",
              " 'B-ADVP': 8,\n",
              " 'I-ADVP': 9,\n",
              " 'I-ADJP': 10,\n",
              " 'I-SBAR': 11,\n",
              " 'I-PP': 12,\n",
              " 'B-PRT': 13,\n",
              " 'B-LST': 14,\n",
              " 'B-INTJ': 15,\n",
              " 'I-INTJ': 16,\n",
              " 'B-CONJP': 17,\n",
              " 'I-CONJP': 18,\n",
              " '<PAD_TAG>': 19,\n",
              " 'I-PRT': 20,\n",
              " 'B-UCP': 21,\n",
              " 'I-UCP': 22}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ6wIRowJzv6",
        "outputId": "1eb887ec-68eb-49e9-caf0-f267a2e9f95b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chancellor O\n",
            "of B-PP\n",
            "the B-NP\n",
            "exchequer I-NP\n",
            "nigel B-NP\n",
            "lawson I-NP\n",
            "'s B-NP\n",
            "restated I-NP\n",
            "commitment I-NP\n",
            "to B-PP\n",
            "a B-NP\n",
            "firm I-NP\n",
            "monetary I-NP\n",
            "policy I-NP\n",
            "has B-VP\n",
            "helped I-VP\n",
            "to I-VP\n",
            "prevent I-VP\n",
            "a B-NP\n",
            "freefall I-NP\n",
            "in B-PP\n",
            "sterling B-NP\n",
            "over B-PP\n",
            "the B-NP\n",
            "past I-NP\n",
            "week I-NP\n",
            ". O\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(X[1])):\n",
        "    print(X[1][i], Y[1][i])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1DELI8zgVgo",
        "outputId": "67f90a3f-7322-4439-f772-1cf5facd0927"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = set()\n",
        "for i in range(len(Y)):\n",
        "  a= set(Y[i])\n",
        "  p=p.union(a)\n",
        "len(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Cj5NlmKk2KH",
        "outputId": "f298d477-2642-4640-92c1-780595ca7009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "!pip install gensim"
      ],
      "metadata": {
        "id": "UgwSHfu3N1cR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40fc437b-5246-41ea-8c0b-d1ba2ef94561"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.9/dist-packages (4.3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim) (6.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import Word2vEC embeddings"
      ],
      "metadata": {
        "id": "NeQg0lbBUc4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n"
      ],
      "metadata": {
        "id": "9lGE5eOkM5c3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import gensim.models.keyedvectors as kv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRvYjC88X2Kf",
        "outputId": "686149b0-b685-4f74-a7b1-674f2dc54f1c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.test.utils import datapath, get_tmpfile"
      ],
      "metadata": {
        "id": "NLrHCAzEg18n"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec"
      ],
      "metadata": {
        "id": "Uri6hTpbhSHh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = datapath('/content/gdrive/MyDrive/pre trained word2vec/glove.6B.300d.txt')\n",
        "output_path = tmp_file = get_tmpfile(\"put_word2vec.txt\")\n",
        "_ = glove2word2vec(model_path, tmp_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8F-st9ddkSp",
        "outputId": "41b04f81-91d7-43f2-9c35-916175362938"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-4f176eac3f4d>:3: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
            "  _ = glove2word2vec(model_path, tmp_file)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = kv.KeyedVectors.load_word2vec_format(tmp_file)"
      ],
      "metadata": {
        "id": "TK_7ZHH7iC0M"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert each word in each sentence to its word embedding\n",
        "embeddings = []\n",
        "for sentence in X:\n",
        "    sentence_embeddings = []\n",
        "    for word in sentence:\n",
        "        if word in model:\n",
        "            sentence_embeddings.append(model[word])\n",
        "    embeddings.append(sentence_embeddings)\n",
        "\n",
        "print(len(embeddings[1][1]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dfs3R2dZWCvA",
        "outputId": "d7362c8c-145c-4395-c2de-1fc95fab8ce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[1][0],embeddings[1][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "dUmOUEpMpT6A",
        "outputId": "2cbaae68-8c89-4cf5-d48a-fb816967b329"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-dcfda4581e6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'embeddings' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(embeddings[0][1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm2z-RlBuug9",
        "outputId": "f0986fbe-a048-42bd-b3d7-a020d57d27b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "BrxGhhjO7kRB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result=model.most_similar(positive=['woman','king'], negative=['man'], topn=10)\n",
        "result"
      ],
      "metadata": {
        "id": "RnMUdrvINAPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89047fe4-b800-45e6-cf83-7955e4cbfe09"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.6713277101516724),\n",
              " ('princess', 0.5432624816894531),\n",
              " ('throne', 0.5386103987693787),\n",
              " ('monarch', 0.5347574949264526),\n",
              " ('daughter', 0.49802514910697937),\n",
              " ('mother', 0.49564430117607117),\n",
              " ('elizabeth', 0.4832652509212494),\n",
              " ('kingdom', 0.47747090458869934),\n",
              " ('prince', 0.4668239951133728),\n",
              " ('wife', 0.46473270654678345)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.utils.data import DataLoader,Dataset\n",
        "# class BIOData(Dataset):\n",
        "#     def __init__(self, data):\n",
        "#         self.data = data\n",
        "        \n",
        "#     def __len__(self):\n",
        "#         return len(self.data)\n",
        "    \n",
        "#     def __getitem__(self, index):\n",
        "#         sentence, tags = self.data[index]\n",
        "#         sentence_vec = torch.tensor(sentence, dtype=torch.float32)\n",
        "#         tags_vec = torch.tensor(tags, dtype=torch.long)\n",
        "#         return sentence_vec, tags_vec"
      ],
      "metadata": {
        "id": "4UT6fDCwujDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## convert words into word embeddings in form of tensors\n",
        "## convert targets into one-hot form of tensors\n",
        "\n",
        "## And then we will make dataloaders"
      ],
      "metadata": {
        "id": "5H7WfPF5UODc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "class EmbeddingsDataset(Dataset):\n",
        "    def __init__(self, embeddings_list,targets):\n",
        "        self.embeddings_list = embeddings_list\n",
        "        self.entities = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample_embeddings = self.embeddings_list[idx]\n",
        "        sample_targets = self.entities[idx]\n",
        "        return sample_embeddings,sample_targets\n"
      ],
      "metadata": {
        "id": "Q_SqBM84TEi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = EmbeddingsDataset(embeddings,Y)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n"
      ],
      "metadata": {
        "id": "EBa2KtCuqgFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for em,t in dataloader:\n",
        "  print(em[0].size())\n",
        "  print(t[0],t[1])\n",
        "  break"
      ],
      "metadata": {
        "id": "QVsSPC1bshb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Model"
      ],
      "metadata": {
        "id": "H4lmyD1BUoys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_size = 300\n",
        "hidden_size = 64\n",
        "num_classes = 22\n",
        "num_layers = 1\n",
        "kernel_size = 3\n",
        "stride = 1\n",
        "padding = 1"
      ],
      "metadata": {
        "id": "hKxnKX68U_7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTM_NER(nn.Module):\n",
        "    def __init__(self, n_vocab, n_embed, n_hidden, n_layers, n_tags, weights):\n",
        "        super(BiLSTM_NER, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.n_hidden = n_hidden\n",
        "        self.embedding = nn.Embedding(n_vocab, n_embed)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(weights))\n",
        "        self.lstm = nn.LSTM(n_embed, n_hidden, n_layers, bidirectional=True, dropout=0.5)\n",
        "        self.fc = nn.Linear(n_hidden * 2, n_tags)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embedding(inputs)\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(inputs), 1, -1))\n",
        "        tag_space = self.fc(lstm_out.view(len(inputs), -1))\n",
        "        tag_scores = nn.functional.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ],
      "metadata": {
        "id": "NWtHSrGjVBM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "cnnmodel = CNNModel(300, hidden_size, num_classes, num_layers, kernel_size, stride, padding)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(cnnmodel.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "HXTUwEJHVHKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# class BIOTaggedSentenceDataset(Dataset):\n",
        "#     def __init__(self, X, Y):\n",
        "#         self.X = X\n",
        "#         self.Y = Y\n",
        "        \n",
        "#     def __len__(self):\n",
        "#         return len(self.X)\n",
        "    \n",
        "#     def __getitem__(self, index):\n",
        "#         sentence = self.X[index]\n",
        "#         tags = self.Y[index]\n",
        "#         sentence_vec = torch.tensor(sentence, dtype=torch.long)\n",
        "#         tags_vec = torch.tensor([TAG_TO_IDX[tag] for tag in tags], dtype=torch.long)\n",
        "#         return sentence_vec, tags_vec\n",
        "    \n",
        "# # Example training data\n",
        "# X = [\n",
        "#     ['John', 'likes', 'apples'],\n",
        "#     ['Mary', 'hates', 'bananas']\n",
        "# ]\n",
        "# Y = [\n",
        "#     ['B-PER', 'O', 'O'],\n",
        "#     ['B-PER', 'O', 'O']\n",
        "# ]\n",
        "\n",
        "# # Create a Dataset and DataLoader\n",
        "# train_dataset = BIOTaggedSentenceDataset(X, Y)\n",
        "# batch_size = 2\n",
        "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "XCK6aONhF1rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "a7KSXDT0UycM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(dataloader):\n",
        "        # Forward pass\n",
        "        outputs = cnnmodel(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Print statistics\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "id": "c71toj3-g6pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the model using Devset for hyperparameter tuning"
      ],
      "metadata": {
        "id": "ZaAo-MB9VOgM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rgwUH_cRVON8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the model finally"
      ],
      "metadata": {
        "id": "rOvLGN1bVUFV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yFZTknb_VYkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "class NERDataset(Dataset):\n",
        "    def __init__(self, sentences, tags, word2vec, label_encoder,max_seq_len=15):\n",
        "        self.sentences = sentences\n",
        "        self.tags = tags\n",
        "        self.word2vec = word2vec\n",
        "        self.label_encoder = label_encoder\n",
        "        self.max_seq_len = max_seq_len\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = self.sentences[idx]\n",
        "        tag = self.tags[idx]\n",
        "        # Encode the sentence using word2vec embeddings\n",
        "        embedded_sentence = []\n",
        "        for word in sentence:\n",
        "            if word in self.word2vec:\n",
        "                embedding = self.word2vec[word]\n",
        "            else:\n",
        "                embedding = self.word2vec[\"the\"]\n",
        "            embedded_sentence.append(embedding)\n",
        "        # Pad sentence embeddings\n",
        "        if len(embedded_sentence) < self.max_seq_len:\n",
        "            padding = [self.word2vec[\"pad\"]] * (self.max_seq_len - len(embedded_sentence))\n",
        "            embedded_sentence.extend(padding)\n",
        "        else:\n",
        "            embedded_sentence = embedded_sentence[:self.max_seq_len]\n",
        "\n",
        "        # Pad tags with a special padding token\n",
        "        if len(tag) < self.max_seq_len:\n",
        "            padding = [\"<PAD_TAG>\"] * (self.max_seq_len - len(tag))\n",
        "            tag.extend(padding)\n",
        "        else:\n",
        "            tag = tag[:self.max_seq_len]\n",
        "        # Encode the tags using the label encoder\n",
        "        encoded_tags = [tags[p] for p in tag]\n",
        "\n",
        "        return torch.FloatTensor(embedded_sentence), torch.tensor(encoded_tags, dtype=torch.long)"
      ],
      "metadata": {
        "id": "7g94At1qgZ3i"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "all_tags = set([tag for tag_list in tags for tag in tag_list])\n",
        "label_encoder.fit(list(all_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "Zc64VUwSgkWC",
        "outputId": "d53077db-bb26-4eaa-c24f-6adb60104d88"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ],
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class NERDataset(Dataset):\n",
        "#     def __init__(self, sentences, tags, word2vec_model):\n",
        "#         self.sentences = sentences\n",
        "#         self.tags = tags\n",
        "#         self.word2vec_model = word2vec_model\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.sentences)\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         sentence = self.sentences[index]\n",
        "#         tag = self.tags[index]\n",
        "\n",
        "#         # Convert words to embeddings\n",
        "#         sentence_embeddings = [self.word2vec_model[word] for word in sentence]\n",
        "\n",
        "#         return torch.FloatTensor(sentence_embeddings), torch.LongTensor(tag)\n",
        "# class NERDataset(Dataset):\n",
        "#     def __init__(self, sentences, tags, word2vec, max_seq_len=50):\n",
        "#         self.sentences = sentences\n",
        "#         self.tags = tags\n",
        "#         self.word2vec = word2vec\n",
        "#         self.max_seq_len = max_seq_len\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.sentences)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         sentence = self.sentences[idx]\n",
        "#         tag=self.tags[Y[idx]]\n",
        "#         sentence_embedding = []\n",
        "        \n",
        "#         for word in sentence:\n",
        "#             if word in self.word2vec:\n",
        "#                 embedding = self.word2vec[word]\n",
        "#             else:\n",
        "#                 embedding = self.word2vec[\"the\"]\n",
        "#             sentence_embedding.append(embedding)\n",
        "        \n",
        "        # # Pad sentence embeddings\n",
        "        # if len(sentence_embedding) < self.max_seq_len:\n",
        "        #     padding = [self.word2vec[\"pad\"]] * (self.max_seq_len - len(sentence_embedding))\n",
        "        #     sentence_embedding.extend(padding)\n",
        "        # else:\n",
        "        #     sentence_embedding = sentence_embedding[:self.max_seq_len]\n",
        "\n",
        "        # # Pad tags with a special padding token\n",
        "        # if len(tag) < self.max_seq_len:\n",
        "        #     padding = [\"<PAD_TAG>\"] * (self.max_seq_len - len(tag))\n",
        "        #     tag.extend(padding)\n",
        "        # else:\n",
        "        #     tag = tag[:self.max_seq_len]\n",
        "\n",
        "        # return torch.FloatTensor(sentence_embedding), tag\n",
        "\n",
        "\n",
        "\n",
        "class BiLSTMNER(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(BiLSTMNER, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
        "\n",
        "    def forward(self, input):\n",
        "        lstm_out, _ = self.lstm(input.view(len(input), 1, -1))\n",
        "        tag_space = self.fc(lstm_out.view(len(input), -1))\n",
        "        return tag_space"
      ],
      "metadata": {
        "id": "OwJq3WjwU2U2"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = NERDataset(X,Y, model,label_encoder)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "dVQEHy0bVBNW"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z_as1IxmLP3",
        "outputId": "ff71ff29-934e-4dfb-fa71-48b1e8f23502"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[[-0.3966, -0.0794,  0.2449,  ..., -0.0330,  0.0562,  0.6865],\n",
              "          [-0.0666,  0.7397,  0.0369,  ..., -0.0585, -0.2657, -0.2135],\n",
              "          [-0.3260,  0.2583, -0.3910,  ..., -0.5825, -0.3339, -0.0575],\n",
              "          ...,\n",
              "          [-0.4218,  0.0659,  0.1513,  ..., -0.6822,  0.1206, -0.6496],\n",
              "          [-0.1256,  0.0136,  0.1031,  ..., -0.3422, -0.0224,  0.1368],\n",
              "          [-0.0305, -0.2272,  0.3878,  ..., -0.4162, -0.6488,  0.0726]]]),\n",
              " tensor([[ 0,  2,  3,  4,  4,  0,  2,  2,  1,  0,  2,  0,  2,  6, 19]])]"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 4500\n",
        "hidden_size = 128\n",
        "output_size = 15\n",
        "our_model = BiLSTMNER(input_size, hidden_size, output_size)"
      ],
      "metadata": {
        "id": "uOWDitPkVQ4Z"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(our_model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "GCYDW_ijVVl6"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"ahaa\")\n",
        "    for i, (sentence,tag) in enumerate(dataloader):\n",
        "        print('omg')\n",
        "        sentence = Variable(sentence)\n",
        "        tag = Variable(tag)\n",
        "        tag=tag.flatten()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = our_model(sentence)\n",
        "        print(outputs)\n",
        "        loss = criterion(outputs, tag)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "zq5QlLK7VWZZ",
        "outputId": "1a2ca3d8-4196-4984-f741-675b86056018"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ahaa\n",
            "omg\n",
            "tensor([[ 0.2886, -0.0753,  0.0822, -0.1233, -0.0037, -0.1135,  0.1117,  0.0332,\n",
            "          0.0103, -0.1060,  0.0049,  0.1197,  0.1939,  0.2082,  0.0566]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-ec94ad322647>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mour_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3025\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (1) to match target batch_size (15)."
          ]
        }
      ]
    }
  ]
}