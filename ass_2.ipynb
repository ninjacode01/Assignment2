{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1LdmvdGpXp-wDu3ht2JccjS-noXtK8KCa",
      "authorship_tag": "ABX9TyN77eblMGzXg79Ffgc3Zuh4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ninjacode01/Assignment2/blob/main/ass_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Named Entity Recognition"
      ],
      "metadata": {
        "id": "3dw4688vJ6LC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets start with reading and pre-processing the training dataset\n"
      ],
      "metadata": {
        "id": "lyTqmUiGKFa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone 'https://github.com/ninjacode01/Assignment2'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpBP7EM2KQ2K",
        "outputId": "f510d213-ded8-4c03-8e6a-a5bc5093d9bd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Assignment2'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 18 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (18/18), 728.04 KiB | 3.59 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Assignment2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwP8VpC9Mwlk",
        "outputId": "61d1254f-1041-481c-cd14-b8f34d004816"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Assignment2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(filename):\n",
        "    with open(filename, \"r\") as file:\n",
        "        text = file.readlines()\n",
        "    return text\n",
        "\n",
        "def process_text(text):\n",
        "    X = []\n",
        "    Y = []\n",
        "    sentenceX = []\n",
        "    sentenceY = []\n",
        "    for line in text:\n",
        "        split = line.split(\" \")\n",
        "        if len(split) > 1:\n",
        "            sentenceX.append(split[0].lower())\n",
        "            sentenceY.append(split[1].replace(\"\\n\", \"\"))\n",
        "        else:\n",
        "            X.append(sentenceX)\n",
        "            Y.append(sentenceY)\n",
        "            sentenceX = []\n",
        "            sentenceY = []\n",
        "    return X, Y\n",
        "\n",
        "text = read_file(\"data/train.txt\")\n",
        "X, Y = process_text(text)\n",
        "\n",
        "testing= read_file(\"data/test.txt\")\n",
        "X_test, Y_test= process_text(testing)"
      ],
      "metadata": {
        "id": "SDHXo6ggMudj"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags={}\n",
        "k=0\n",
        "for i in range(len(Y)):\n",
        "  for j in range(len(Y[i])):\n",
        "    if tags.get(Y[i][j])==None:\n",
        "      tags[Y[i][j]]= k\n",
        "      k+=1\n",
        "tags\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfQWWMX-aSw5",
        "outputId": "5a3a8497-6ff6-4446-b977-7878f8b48c94"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-NP': 0,\n",
              " 'B-PP': 1,\n",
              " 'I-NP': 2,\n",
              " 'B-VP': 3,\n",
              " 'I-VP': 4,\n",
              " 'B-SBAR': 5,\n",
              " 'O': 6,\n",
              " 'B-ADJP': 7,\n",
              " 'B-ADVP': 8,\n",
              " 'I-ADVP': 9,\n",
              " 'I-ADJP': 10,\n",
              " 'I-SBAR': 11,\n",
              " 'I-PP': 12,\n",
              " 'B-PRT': 13,\n",
              " 'B-LST': 14,\n",
              " 'B-INTJ': 15,\n",
              " 'I-INTJ': 16,\n",
              " 'B-CONJP': 17,\n",
              " 'I-CONJP': 18,\n",
              " '<PAD_TAG>': 19,\n",
              " 'I-PRT': 20,\n",
              " 'B-UCP': 21,\n",
              " 'I-UCP': 22}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ6wIRowJzv6",
        "outputId": "1eb887ec-68eb-49e9-caf0-f267a2e9f95b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chancellor O\n",
            "of B-PP\n",
            "the B-NP\n",
            "exchequer I-NP\n",
            "nigel B-NP\n",
            "lawson I-NP\n",
            "'s B-NP\n",
            "restated I-NP\n",
            "commitment I-NP\n",
            "to B-PP\n",
            "a B-NP\n",
            "firm I-NP\n",
            "monetary I-NP\n",
            "policy I-NP\n",
            "has B-VP\n",
            "helped I-VP\n",
            "to I-VP\n",
            "prevent I-VP\n",
            "a B-NP\n",
            "freefall I-NP\n",
            "in B-PP\n",
            "sterling B-NP\n",
            "over B-PP\n",
            "the B-NP\n",
            "past I-NP\n",
            "week I-NP\n",
            ". O\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(X[1])):\n",
        "    print(X[1][i], Y[1][i])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1DELI8zgVgo",
        "outputId": "67f90a3f-7322-4439-f772-1cf5facd0927"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = set()\n",
        "for i in range(len(Y)):\n",
        "  a= set(Y[i])\n",
        "  p=p.union(a)\n",
        "len(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Cj5NlmKk2KH",
        "outputId": "f298d477-2642-4640-92c1-780595ca7009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "!pip install gensim"
      ],
      "metadata": {
        "id": "UgwSHfu3N1cR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40fc437b-5246-41ea-8c0b-d1ba2ef94561"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.9/dist-packages (4.3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim) (6.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import Word2vEC embeddings"
      ],
      "metadata": {
        "id": "NeQg0lbBUc4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n"
      ],
      "metadata": {
        "id": "9lGE5eOkM5c3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import gensim.models.keyedvectors as kv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRvYjC88X2Kf",
        "outputId": "686149b0-b685-4f74-a7b1-674f2dc54f1c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.test.utils import datapath, get_tmpfile"
      ],
      "metadata": {
        "id": "NLrHCAzEg18n"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec"
      ],
      "metadata": {
        "id": "Uri6hTpbhSHh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = datapath('/content/gdrive/MyDrive/pre trained word2vec/glove.6B.300d.txt')\n",
        "output_path = tmp_file = get_tmpfile(\"put_word2vec.txt\")\n",
        "_ = glove2word2vec(model_path, tmp_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8F-st9ddkSp",
        "outputId": "41b04f81-91d7-43f2-9c35-916175362938"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-4f176eac3f4d>:3: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
            "  _ = glove2word2vec(model_path, tmp_file)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = kv.KeyedVectors.load_word2vec_format(tmp_file)"
      ],
      "metadata": {
        "id": "TK_7ZHH7iC0M"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert each word in each sentence to its word embedding\n",
        "embeddings = []\n",
        "for sentence in X:\n",
        "    sentence_embeddings = []\n",
        "    for word in sentence:\n",
        "        if word in model:\n",
        "            sentence_embeddings.append(model[word])\n",
        "    embeddings.append(sentence_embeddings)\n",
        "\n",
        "print(len(embeddings[1][1]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dfs3R2dZWCvA",
        "outputId": "3d7a3251-1fee-4a6e-8123-cc3e953c052a"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[1][0],embeddings[1][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUmOUEpMpT6A",
        "outputId": "2a86a818-6a2c-4574-9c07-0aa255ae737e"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chancellor [-1.9598e-01 -2.2278e-01  2.3081e-01 -9.4298e-02 -2.1582e-02 -8.9439e-01\n",
            "  2.9329e-01 -2.7248e-01  1.0140e-01 -1.2988e+00 -1.6568e-01  3.4622e-02\n",
            "  1.0561e-01 -3.2991e-01 -2.8702e-01  8.8516e-02 -1.8614e-01 -4.0949e-01\n",
            "  1.7233e-01  2.4198e-01  2.1979e-01  3.5375e-01  5.4433e-01 -2.0146e-01\n",
            " -2.0864e-01 -4.0381e-02  1.1990e-02  2.0699e-01 -6.8832e-02 -8.9819e-03\n",
            " -3.1481e-01 -6.2470e-01  2.7793e-01  3.4734e-01 -1.1944e+00 -1.0727e-01\n",
            "  3.1606e-01  3.0069e-01 -1.1131e-02  3.5380e-01 -4.7972e-01 -2.3734e-02\n",
            "  1.3781e-01 -7.2490e-01 -9.8616e-02  1.4537e-01 -2.1263e-01 -2.1144e-03\n",
            " -3.4416e-01 -1.0624e+00  1.0349e-02  2.9091e-01 -4.4020e-04 -1.7580e-01\n",
            "  5.5948e-01  1.8447e-01 -5.8080e-02  2.2014e-01  5.2696e-01  4.1167e-01\n",
            " -2.8385e-01  6.9797e-02 -1.1380e-01  1.1693e-01  9.0904e-01 -8.4972e-01\n",
            " -1.9936e-01  1.2959e-01 -4.9531e-01  3.6264e-01 -8.7532e-02  2.6479e-01\n",
            " -2.3816e-01  1.6748e-02  1.4343e-01  1.1095e-01 -3.9928e-01  4.0814e-01\n",
            "  1.1797e-01  6.3095e-01  9.6403e-02  5.6904e-01 -4.3673e-01  5.7984e-01\n",
            "  7.3140e-01  5.6597e-01 -5.4336e-01  7.7655e-01 -7.9375e-02  2.7426e-02\n",
            " -1.5246e-01  8.8717e-02 -2.8354e-01 -5.8119e-02 -1.3729e-02 -3.6726e-02\n",
            "  3.0301e-02  8.5771e-01 -5.7675e-01 -5.1852e-02 -1.6880e-01 -3.9158e-01\n",
            " -5.2057e-01  2.7660e-01 -9.3864e-02  4.2782e-03 -2.8760e-01  7.4950e-02\n",
            "  1.8760e-01 -2.4163e-01  2.2496e-01  4.3513e-01  7.9545e-02  2.8963e-01\n",
            "  1.3477e-01 -2.1513e-01 -6.2906e-02 -5.0021e-01  4.2905e-01 -7.7063e-01\n",
            "  5.7601e-01  4.0968e-01 -1.1389e-01 -3.0125e-01 -8.2081e-02 -5.3379e-02\n",
            " -1.8734e-02  3.5403e-01  5.5772e-01  3.1103e-01 -1.8529e-01  3.7506e-02\n",
            "  1.2106e-01  5.0281e-02 -6.8921e-01 -1.3223e-01 -2.9606e-01 -2.3554e-01\n",
            "  1.4349e-01 -1.2934e-01  9.4354e-03  8.0680e-03 -4.5868e-02  4.0892e-01\n",
            "  6.5193e-01 -1.9932e-01  4.6340e-01 -2.4712e-01  7.4631e-02 -3.2734e-02\n",
            "  1.0032e+00  1.8104e-01  3.8673e-01  5.8424e-01  2.1024e-01  2.2124e-01\n",
            "  1.1356e-01 -5.0076e-01 -5.9162e-01  2.4107e-01  4.7236e-02  6.8370e-01\n",
            "  4.0338e-01 -5.9101e-01 -5.4201e-01  4.8273e-01 -1.7099e-01 -2.2647e-01\n",
            "  2.9687e-01  1.9903e-01  3.5455e-01  1.2016e-01 -6.7502e-01 -5.3251e-01\n",
            "  9.2383e-02  6.0490e-01 -2.5122e-01 -7.3022e-02  4.1916e-01  1.1776e-01\n",
            "  5.8510e-01  1.4283e-01 -2.0312e-02 -5.9181e-01  3.3683e-01 -1.8479e-01\n",
            " -8.5177e-01 -3.6037e-01 -5.8780e-01 -2.0103e-01 -4.6046e-01 -3.6700e-01\n",
            "  2.8764e-01 -1.3741e-01 -2.9761e-01 -5.0821e-02  3.2037e-01  1.1730e-01\n",
            " -1.3013e-02  1.9897e-01  3.7641e-01 -3.0119e-01  1.1824e-02  6.8404e-02\n",
            " -7.2212e-01 -6.2168e-01 -1.0443e-02 -1.0652e-01  2.2427e-01  3.5196e-01\n",
            "  4.7393e-01 -9.4606e-02  5.1763e-01 -5.9458e-01 -3.3822e-02  1.0794e-01\n",
            " -7.0207e-01 -4.6428e-02  3.2059e-01 -8.4891e-01  5.4985e-01  7.8618e-01\n",
            " -1.7619e-01  6.6093e-01 -3.2038e-01  1.1000e-01  5.0440e-01  1.4989e-01\n",
            " -4.5281e-01  2.2241e-01 -4.6187e-02 -1.9612e-01  1.9279e-01  1.1446e-01\n",
            " -1.6411e-01  7.3545e-02  1.5023e-01  5.2489e-01  5.9196e-01 -3.3325e-01\n",
            " -5.3069e-01 -2.0579e-01  5.4547e-01 -1.4334e-01  1.5921e-01  1.0963e+00\n",
            "  1.6845e-01 -2.1273e-01  8.7020e-01 -3.3682e-01  4.4240e-01 -1.9303e-01\n",
            "  5.0324e-01  4.0023e-01  1.0681e-01  1.7619e-01 -6.3505e-02 -2.2344e-01\n",
            "  4.0937e-01 -7.5558e-01 -2.9186e-01 -3.6021e-01  5.5042e-01 -1.6088e-02\n",
            " -6.0363e-01 -5.5184e-01 -5.1373e-01  9.2796e-02 -7.3804e-01 -1.2496e-01\n",
            " -7.1236e-01  3.7574e-01 -4.1230e-01 -1.9844e-01 -1.4768e-01 -2.7882e-01\n",
            "  6.4231e-04  1.3902e-01  8.9808e-01 -4.3882e-01  4.8332e-01  5.7857e-01\n",
            " -8.5246e-02 -6.0383e-01 -1.5193e-01  6.7092e-01 -3.1829e-01  2.6813e-02\n",
            "  4.1775e-02  2.7205e-01  9.8229e-02 -2.5345e-01  8.8171e-02 -7.0320e-03\n",
            " -1.5709e-03 -2.4755e-01  1.3931e-01 -5.5107e-01 -3.6191e-01  6.8114e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(embeddings[0][1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm2z-RlBuug9",
        "outputId": "3da650df-b9de-4b3b-be82-9a7304e5b3ea"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "BrxGhhjO7kRB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result=model.most_similar(positive=['woman','king'], negative=['man'], topn=10)\n",
        "result"
      ],
      "metadata": {
        "id": "RnMUdrvINAPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59f4d450-53e5-4f41-8ca3-fa7899b2387f"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.6713277101516724),\n",
              " ('princess', 0.5432624816894531),\n",
              " ('throne', 0.5386103987693787),\n",
              " ('monarch', 0.5347574949264526),\n",
              " ('daughter', 0.49802514910697937),\n",
              " ('mother', 0.49564430117607117),\n",
              " ('elizabeth', 0.4832652509212494),\n",
              " ('kingdom', 0.47747090458869934),\n",
              " ('prince', 0.4668239951133728),\n",
              " ('wife', 0.46473270654678345)]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "class NERDataset(Dataset):\n",
        "    def __init__(self, sentences, tags, word2vec, label_encoder,max_seq_len=15):\n",
        "        self.sentences = sentences\n",
        "        self.tags = tags\n",
        "        self.word2vec = word2vec\n",
        "        self.label_encoder = label_encoder\n",
        "        self.max_seq_len = max_seq_len\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = self.sentences[idx]\n",
        "        tag = self.tags[idx]\n",
        "        # Encode the sentence using word2vec embeddings\n",
        "        embedded_sentence = []\n",
        "        for word in sentence:\n",
        "            if word in self.word2vec:\n",
        "                embedding = self.word2vec[word]\n",
        "            else:\n",
        "                embedding = self.word2vec[\"the\"]\n",
        "            embedded_sentence.append(embedding)\n",
        "        # Pad sentence embeddings\n",
        "        if len(embedded_sentence) < self.max_seq_len:\n",
        "            padding = [self.word2vec[\"pad\"]] * (self.max_seq_len - len(embedded_sentence))\n",
        "            embedded_sentence.extend(padding)\n",
        "        else:\n",
        "            embedded_sentence = embedded_sentence[:self.max_seq_len]\n",
        "\n",
        "        # Pad tags with a special padding token\n",
        "        if len(tag) < self.max_seq_len:\n",
        "            padding = [\"<PAD_TAG>\"] * (self.max_seq_len - len(tag))\n",
        "            tag.extend(padding)\n",
        "        else:\n",
        "            tag = tag[:self.max_seq_len]\n",
        "        # Encode the tags using the label encoder\n",
        "        encoded_tags = [tags[p] for p in tag]\n",
        "\n",
        "        # targets = []\n",
        "        # for sentence in train_data:\n",
        "        #     targets.append(torch.tensor([tags[m] for m in tag]))\n",
        "\n",
        "        return torch.FloatTensor(embedded_sentence), torch.tensor(encoded_tags, dtype=torch.float)"
      ],
      "metadata": {
        "id": "7g94At1qgZ3i"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "all_tags = set([tag for tag_list in tags for tag in tag_list])\n",
        "label_encoder.fit(list(all_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "Zc64VUwSgkWC",
        "outputId": "d53077db-bb26-4eaa-c24f-6adb60104d88"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ],
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class NERDataset(Dataset):\n",
        "#     def __init__(self, sentences, tags, word2vec_model):\n",
        "#         self.sentences = sentences\n",
        "#         self.tags = tags\n",
        "#         self.word2vec_model = word2vec_model\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.sentences)\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         sentence = self.sentences[index]\n",
        "#         tag = self.tags[index]\n",
        "\n",
        "#         # Convert words to embeddings\n",
        "#         sentence_embeddings = [self.word2vec_model[word] for word in sentence]\n",
        "\n",
        "#         return torch.FloatTensor(sentence_embeddings), torch.LongTensor(tag)\n",
        "# class NERDataset(Dataset):\n",
        "#     def __init__(self, sentences, tags, word2vec, max_seq_len=50):\n",
        "#         self.sentences = sentences\n",
        "#         self.tags = tags\n",
        "#         self.word2vec = word2vec\n",
        "#         self.max_seq_len = max_seq_len\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.sentences)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         sentence = self.sentences[idx]\n",
        "#         tag=self.tags[Y[idx]]\n",
        "#         sentence_embedding = []\n",
        "        \n",
        "#         for word in sentence:\n",
        "#             if word in self.word2vec:\n",
        "#                 embedding = self.word2vec[word]\n",
        "#             else:\n",
        "#                 embedding = self.word2vec[\"the\"]\n",
        "#             sentence_embedding.append(embedding)\n",
        "        \n",
        "        # # Pad sentence embeddings\n",
        "        # if len(sentence_embedding) < self.max_seq_len:\n",
        "        #     padding = [self.word2vec[\"pad\"]] * (self.max_seq_len - len(sentence_embedding))\n",
        "        #     sentence_embedding.extend(padding)\n",
        "        # else:\n",
        "        #     sentence_embedding = sentence_embedding[:self.max_seq_len]\n",
        "\n",
        "        # # Pad tags with a special padding token\n",
        "        # if len(tag) < self.max_seq_len:\n",
        "        #     padding = [\"<PAD_TAG>\"] * (self.max_seq_len - len(tag))\n",
        "        #     tag.extend(padding)\n",
        "        # else:\n",
        "        #     tag = tag[:self.max_seq_len]\n",
        "\n",
        "        # return torch.FloatTensor(sentence_embedding), tag\n"
      ],
      "metadata": {
        "id": "OwJq3WjwU2U2"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTMNER(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(BiLSTMNER, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, bidirectional=True,dropout=0.5)\n",
        "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
        "\n",
        "    def forward(self, input):\n",
        "        lstm_out, _ = self.lstm(input.view(len(input), 1, -1))\n",
        "        tag_space = self.fc(lstm_out.view(len(input), -1))\n",
        "        tag_scores = nn.functional.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ],
      "metadata": {
        "id": "zL6B6K0xpi7w"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = NERDataset(X,Y, model,label_encoder)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "dVQEHy0bVBNW"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z_as1IxmLP3",
        "outputId": "ff71ff29-934e-4dfb-fa71-48b1e8f23502"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[[-0.3966, -0.0794,  0.2449,  ..., -0.0330,  0.0562,  0.6865],\n",
              "          [-0.0666,  0.7397,  0.0369,  ..., -0.0585, -0.2657, -0.2135],\n",
              "          [-0.3260,  0.2583, -0.3910,  ..., -0.5825, -0.3339, -0.0575],\n",
              "          ...,\n",
              "          [-0.4218,  0.0659,  0.1513,  ..., -0.6822,  0.1206, -0.6496],\n",
              "          [-0.1256,  0.0136,  0.1031,  ..., -0.3422, -0.0224,  0.1368],\n",
              "          [-0.0305, -0.2272,  0.3878,  ..., -0.4162, -0.6488,  0.0726]]]),\n",
              " tensor([[ 0,  2,  3,  4,  4,  0,  2,  2,  1,  0,  2,  0,  2,  6, 19]])]"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 4500\n",
        "hidden_size = 128\n",
        "output_size = 15\n",
        "our_model = BiLSTMNER(input_size, hidden_size, output_size)"
      ],
      "metadata": {
        "id": "uOWDitPkVQ4Z"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(our_model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "GCYDW_ijVVl6"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 1\n",
        "for epoch in range(num_epochs):\n",
        "    print('yahoo')\n",
        "    for i, (sentence,tag) in enumerate(dataloader):\n",
        "        sentence = Variable(sentence)\n",
        "        tag = Variable(tag)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = our_model(sentence)\n",
        "        loss = criterion(outputs, tag)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 500 == 0:\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq5QlLK7VWZZ",
        "outputId": "d919b8c9-0b8d-4d2b-f0b7-986360924441"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yahoo\n",
            "Epoch [1/1], Loss: 111.2582\n",
            "Epoch [1/1], Loss: 92.3384\n",
            "Epoch [1/1], Loss: 130.3026\n",
            "Epoch [1/1], Loss: 56.5860\n",
            "Epoch [1/1], Loss: 85.7520\n",
            "Epoch [1/1], Loss: 74.6795\n",
            "Epoch [1/1], Loss: 242.3891\n",
            "Epoch [1/1], Loss: 609.7780\n",
            "Epoch [1/1], Loss: 84.7919\n",
            "Epoch [1/1], Loss: 87.9431\n",
            "Epoch [1/1], Loss: 203.0366\n",
            "Epoch [1/1], Loss: 86.6113\n",
            "Epoch [1/1], Loss: 100.9308\n",
            "Epoch [1/1], Loss: 93.2075\n",
            "Epoch [1/1], Loss: 53.3686\n",
            "Epoch [1/1], Loss: 199.3447\n",
            "Epoch [1/1], Loss: 89.3730\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3WXaoflK2VWE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}